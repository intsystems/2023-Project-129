\documentclass{article}
\usepackage{arxiv}

\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}
\usepackage{amsmath}



\title{Spatiotemporal forecasting with convolutions and tensor decomposition}

\author{ David S.~Hippocampus\thanks{Use footnote for providing further
		information about author (webpage, alternative
		address)---\emph{not} for acknowledging funding agencies.} \\
	Department of Computer Science\\
	Cranberry-Lemon University\\
	Pittsburgh, PA 15213 \\
	\texttt{hippo@cs.cranberry-lemon.edu} \\
	%% examples of more authors
	\And
	Elias D.~Striatum \\
	Department of Electrical Engineering\\
	Mount-Sheikh University\\
	Santa Narimana, Levand \\
	\texttt{stariate@ee.mount-sheikh.edu} \\
	%% \AND
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
}
\date{}

\renewcommand{\shorttitle}{\textit{arXiv} Template}

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
pdftitle={A template for the arxiv style},
pdfsubject={q-bio.NC, q-bio.QM},
pdfauthor={David S.~Hippocampus, Elias D.~Striatum},
pdfkeywords={First keyword, Second keyword, More},
}

\begin{document}
\maketitle

\begin{abstract}
Tensor based time series decomposition methods based on singular spectrum analysis showed great results in both denoising and interpretability. Several forecasting techniques based on them were already explored, yet none provided simultaneously accurate, stable and computationally cheap inferring. After an in-depth study of well known models we facilitated a new one comprising all three requirements for non-stationary quasi-periodic time series. The model was then tested on real-life data of electricity consumption and other well-explored datasets. 
\end{abstract}


\keywords{First keyword \and Second keyword \and More}

\section{Introduction}
Singular spectrum analysis (SSA) is a method widely used in the past decades in different areas, from economics to biology and social science [1].  One of main advantages is its ability to extract underlying frequencies from complex and multidimensional data, resulting in  variable number of components. SSA consists of two main stages: decomposition and reconstruction, both adjustable in terms of methods and hyperparameters used.

Its tensor modification (TSSA) offers [2] a more robust and accurate results by converting a series into a tensor and using PARAFAC decomposition instead of usual SVD. It optimizes usage of information initially available to a model in cost of working with more multidimensional data SSA does. The problem of reconstruction is left untouched however.

Empirical mode decomposition (EMD) can then be used  to supervise TSSA, giving us TSSA-EMD[3]. It provides a better way to identify the number of frequency components within each subspace. With such enhancement algorithms achieves [4] a distinguishable growth in accuracy of signal reconstruction with denoising, leaving other methods far behind in particular tasks.

The problem of forecasting time series has not yet being mentioned. Basic SSA shows [5] adequate results when working with series of constant-limited variation function. However it becomes highly unstable in two basic cases. With several outliers already false frequencies are extracted at decomposition stage, what does not lead to reconstruction defects but enforces unacceptable error even at earlier points of prediction. A variation growth affects SSA the same way, usually creating frequencies of much higher amplitude than are expected. That makes the early predictions seem accurate, yet giving unrealistic forecast long-wise.

To conclude, SSA is a powerful but limited method.

At the same time SSA does not utilize spatial information. Given a set of parallel time series it is meant to decompose each separately. TSSA instead can show better performance by working with them as with a whole dataset. Knowing this we experiment to determine the difference between SSA and TSSA forecasting and try to create a robust model of signal decomposition, reconstruction and prediction.
\section{Problem}
\label{sec:Problem}

Let \(X = \left[x_1, x_2, ..., x_n\right]\) be a 1D time series, namely a vector. We suppose \(X\) has no trend, is quasi-periodic and it's phase trajectory is stationary.

A parametric function \(f_r\) evaluating next \(r\) unknown time series values \([\widehat{x}_{n+1}, ..., \widehat{x}_{n+r}]\) at the time moment \(t + 1\) given prior series observations \(X\) is called the forecasting model:
\begin{gather}
	f_r(\widehat{w}, X) = \left[\widehat{x}_{n+1}, ..., \widehat{x}_{n+r}\right]. \\
	X^{\widehat{r}} = \left[x_1, x_2, ..., x_n, \widehat{x}_{n+1}, ..., \widehat{x}_{n+r}\right].
\end{gather}

The parameters \(\widehat{w}\) are obtained through optimization of a loss function specific for a dataset and a task, \(r\) is a hyperparameter for the model.

The goal is, using one or several forecasting models with a prediction strategy (described in 2.1) resulting in a final model \(f\), compute next \(h\) unknown time series values, with \(h\) possibly bigger than \(r\). We are to minimize a loss function \(\mathcal{L}\) when given a realization of true future values of time series \(X^{\underline{h}} = \left[ x_1, x_2, \dots, x_n, x_{n+1}, \dots, x_{n+h} \right]\) :
\begin{gather}
	X^{\widehat{h}} = f(X) \notag \\
	\mathcal{L}\left( X^{\underline{h}}, X^{\widehat{h}} \right) \rightarrow \min_f
\end{gather}

\subsection{Prediction strategies}

Two common method are explored.

Recursive strategy uses forecasting model \(f = f_r\) until \(h\) following values for \(X\) are predicted:
\begin{gather}
	X^{\widehat{r}} = f(\widehat{w}, X), \notag \\
	X^{\widehat{2r}} = f(\widehat{w}, X^{\widehat{r}}),\notag \\
	\dots, \\
	X^{\widehat{kr}} = f(\widehat{w}, X^{\widehat{(k-1)r}}).\notag
\end{gather}
Where \( k = \lceil \frac{h}{r} \rceil.\)

Straight strategy requires \(k\) separate models, each independently predicting \(r\) values:
\begin{gather}
	X^{\widehat{r, 1}} = f_1(\widehat{w}, X), \notag \\
	X^{\widehat{r, 2}} = f(\widehat{w}, X), \notag \\
	\dots, \\
	X^{\widehat{r, k}} = f(\widehat{w}, X), \notag \\
	X^{\widehat{kr}} = concatinate(X, X^{\widehat{r, 1}}, \dots, X^{\widehat{r, k}}) \notag
\end{gather}

[Pluses and minuses of both are explained]

\subsection{SSA and TSSA}

Copypaste from https://sci-hub.ru/10.1109/mlsp.2013.6661921 could be found here

\subsection{Forecasting models based on SSA and TSSA}

Copypaste from [Time series SSA forecasting] tutrial link from LinkReview could be found here.

No idea on how to predict with TSSA - we are to explore this I suppose

\section{Examples of citations, figures, tables, references}
\label{sec:others}

\subsection{Citations}
Citations use \verb+natbib+. The documentation may be found at
\begin{center}
	\url{http://mirrors.ctan.org/macros/latex/contrib/natbib/natnotes.pdf}
\end{center}

Here is an example usage of the two main commands (\verb+citet+ and \verb+citep+): Some people thought a thing \citep{kour2014real, hadash2018estimate} but other people thought something else \citep{kour2014fast}. Many people have speculated that if we knew exactly why \citet{kour2014fast} thought this\dots

\subsection{Figures}
\lipsum[10]
See Figure \ref{fig:fig1}. Here is how you add footnotes. \footnote{Sample of the first footnote.}
\lipsum[11]

\begin{figure}
	\centering
	
	\caption{Sample figure caption.}
	\label{fig:fig1}
\end{figure}

\subsection{Tables}
See awesome Table~\ref{tab:table}.

The documentation for \verb+booktabs+ (`Publication quality tables in LaTeX') is available from:
\begin{center}
	\url{https://www.ctan.org/pkg/booktabs}
\end{center}


\begin{table}
	\caption{Sample table title}
	\centering
	\begin{tabular}{lll}
		\toprule
		\multicolumn{2}{c}{Part}                   \\
		\cmidrule(r){1-2}
		Name     & Description     & Size ($\mu$m) \\
		\midrule
		Dendrite & Input terminal  & $\sim$100     \\
		Axon     & Output terminal & $\sim$10      \\
		Soma     & Cell body       & up to $10^6$  \\
		\bottomrule
	\end{tabular}
	\label{tab:table}
\end{table}

\subsection{Lists}
\begin{itemize}
	\item Lorem ipsum dolor sit amet
	\item consectetur adipiscing elit.
	\item Aliquam dignissim blandit est, in dictum tortor gravida eget. In ac rutrum magna.
\end{itemize}


\bibliographystyle{unsrtnat}
\bibliography{references}

\end{document}